{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oHj4dQu3LfEp",
        "outputId": "da096bed-1156-4c13-f22f-d2b14b332af7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- 1. CONFIGURACIÓN E INICIO DE LA DESCARGA ---\n",
            "Mounted at /content/drive\n",
            "Carpeta creada en Drive: /content/drive/MyDrive/Modelos_Perceptron_Fraude/\n",
            "Using Colab cache for faster access to the 'creditcardfraud' dataset.\n",
            "✅ Dataset descargado y cargado desde: /kaggle/input/creditcardfraud/creditcard.csv\n",
            "Forma del Dataset: (284807, 31)\n",
            "\n",
            "--- 2. PRE-PROCESAMIENTO ---\n",
            "Features escaladas correctamente (StandardScaler).\n",
            "Datos divididos: Entrenamiento=199364, Prueba=85443\n",
            "\n",
            "\n",
            "#################################################################\n",
            "## INICIO DE LOS EXPERIMENTOS DEL PERCEPTRÓN 3: VARIACIÓN DE FEATURES\n",
            "#################################################################\n",
            "\n",
            "--- MODELO_BASE_FEATURES_A (Features: 30) ---\n",
            "✅ Modelo GUARDADO en Google Drive en: /content/drive/MyDrive/Modelos_Perceptron_Fraude/MODELO_BASE_FEATURES_A_LR0p01.joblib\n",
            "Features utilizadas: Time, V1, V2, V3, V4...\n",
            "Tasa de Aprendizaje (eta0): 0.01\n",
            "Recall (Clase 1 - Fraude): 0.7703\n",
            "Precisión (Clase 1 - Fraude): 0.7037\n",
            "\n",
            "Reporte de Clasificación:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "Legítimo (0)       1.00      1.00      1.00     85295\n",
            "  Fraude (1)       0.70      0.77      0.74       148\n",
            "\n",
            "    accuracy                           1.00     85443\n",
            "   macro avg       0.85      0.88      0.87     85443\n",
            "weighted avg       1.00      1.00      1.00     85443\n",
            "\n",
            "\n",
            "--- PERCEPTRON_3_VARIACION_B (Features: 16) ---\n",
            "✅ Modelo GUARDADO en Google Drive en: /content/drive/MyDrive/Modelos_Perceptron_Fraude/PERCEPTRON_3_VARIACION_B_LR0p01.joblib\n",
            "Features utilizadas: Time, Amount, V1, V2, V3...\n",
            "Tasa de Aprendizaje (eta0): 0.01\n",
            "Recall (Clase 1 - Fraude): 0.6959\n",
            "Precisión (Clase 1 - Fraude): 0.8047\n",
            "\n",
            "Reporte de Clasificación:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "Legítimo (0)       1.00      1.00      1.00     85295\n",
            "  Fraude (1)       0.80      0.70      0.75       148\n",
            "\n",
            "    accuracy                           1.00     85443\n",
            "   macro avg       0.90      0.85      0.87     85443\n",
            "weighted avg       1.00      1.00      1.00     85443\n",
            "\n",
            "\n",
            "--- PERCEPTRON_3_VARIACION_C (Features: 9) ---\n",
            "✅ Modelo GUARDADO en Google Drive en: /content/drive/MyDrive/Modelos_Perceptron_Fraude/PERCEPTRON_3_VARIACION_C_LR0p01.joblib\n",
            "Features utilizadas: Time, Amount, V4, V11, V12...\n",
            "Tasa de Aprendizaje (eta0): 0.01\n",
            "Recall (Clase 1 - Fraude): 0.3986\n",
            "Precisión (Clase 1 - Fraude): 0.7763\n",
            "\n",
            "Reporte de Clasificación:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "Legítimo (0)       1.00      1.00      1.00     85295\n",
            "  Fraude (1)       0.78      0.40      0.53       148\n",
            "\n",
            "    accuracy                           1.00     85443\n",
            "   macro avg       0.89      0.70      0.76     85443\n",
            "weighted avg       1.00      1.00      1.00     85443\n",
            "\n",
            "\n",
            "\n",
            "#################################################################\n",
            "## ¡EXPERIMENTO FINALIZADO!\n",
            "Los modelos .joblib han sido guardados en su Drive en: /content/drive/MyDrive/Modelos_Perceptron_Fraude/\n",
            "#################################################################\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import joblib\n",
        "\n",
        "# Bibliotecas de Google Colab y Kaggle\n",
        "from google.colab import drive\n",
        "import kagglehub\n",
        "\n",
        "# Bibliotecas de Scikit-learn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import Perceptron\n",
        "from sklearn.metrics import recall_score, precision_score, classification_report\n",
        "\n",
        "\n",
        "# --- 1. CONFIGURACIÓN Y DESCARGA DE DATOS ---\n",
        "print(\"--- 1. CONFIGURACIÓN E INICIO DE LA DESCARGA ---\")\n",
        "\n",
        "# Montar Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Definir y crear la ruta de guardado en Drive\n",
        "DRIVE_PATH = '/content/drive/MyDrive/Modelos_Perceptron_Fraude/'\n",
        "if not os.path.exists(DRIVE_PATH):\n",
        "    os.makedirs(DRIVE_PATH)\n",
        "    print(f\"Carpeta creada en Drive: {DRIVE_PATH}\")\n",
        "else:\n",
        "    print(f\"Carpeta de Drive ya existe: {DRIVE_PATH}\")\n",
        "\n",
        "# Descargar el dataset de Kaggle\n",
        "# Asegúrese de que sus credenciales de Kaggle estén configuradas en Colab (API token).\n",
        "try:\n",
        "    path = kagglehub.dataset_download(\"mlg-ulb/creditcardfraud\")\n",
        "    file_path = os.path.join(path, 'creditcard.csv')\n",
        "    data = pd.read_csv(file_path)\n",
        "    print(f\"✅ Dataset descargado y cargado desde: {file_path}\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ ERROR al descargar o cargar el dataset. Asegúrese de tener el token de Kaggle configurado.\")\n",
        "    print(f\"Detalle del error: {e}\")\n",
        "    # Detener ejecución si falla la carga\n",
        "    exit()\n",
        "\n",
        "print(\"Forma del Dataset:\", data.shape)\n",
        "\n",
        "\n",
        "# --- 2. PRE-PROCESAMIENTO DE DATOS Y DIVISIÓN ---\n",
        "print(\"\\n--- 2. PRE-PROCESAMIENTO ---\")\n",
        "\n",
        "# Definición de la Variable Objetivo y Features\n",
        "Y = data['Class']\n",
        "X_all = data.drop('Class', axis=1)\n",
        "\n",
        "# Escalado de Features (Crucial para el Perceptrón)\n",
        "scaler = StandardScaler()\n",
        "X_all_scaled = scaler.fit_transform(X_all)\n",
        "X_all_scaled = pd.DataFrame(X_all_scaled, columns=X_all.columns)\n",
        "print(\"Features escaladas correctamente (StandardScaler).\")\n",
        "\n",
        "# División de datos (Entrenamiento y Prueba), estratificado para manejar el desbalance\n",
        "X_train_all, X_test_all, Y_train, Y_test = train_test_split(\n",
        "    X_all_scaled, Y, test_size=0.3, random_state=42, stratify=Y\n",
        ")\n",
        "print(f\"Datos divididos: Entrenamiento={X_train_all.shape[0]}, Prueba={X_test_all.shape[0]}\")\n",
        "\n",
        "\n",
        "# --- 3. DEFINICIÓN DE CONJUNTOS DE FEATURES PARA EL EXPERIMENTO ---\n",
        "\n",
        "# Conjunto A: BASE (Todas las Features)\n",
        "FEATURES_A = X_all_scaled.columns.tolist()\n",
        "\n",
        "# Conjunto B: Modelo 3 - Menor Dimensionalidad (V1-V14 + Time/Amount)\n",
        "FEATURES_B = ['Time', 'Amount'] + [f'V{i}' for i in range(1, 15)]\n",
        "\n",
        "# Conjunto C: Modelo 3 - Features Clave (Basado en relevancia común)\n",
        "FEATURES_C = ['Time', 'Amount', 'V4', 'V11', 'V12', 'V14', 'V16', 'V17', 'V18']\n",
        "\n",
        "\n",
        "# --- 4. FUNCIÓN DE ENTRENAMIENTO, EVALUACIÓN Y GUARDADO ---\n",
        "\n",
        "def train_save_and_evaluate_perceptron(X_train, X_test, Y_train, Y_test, features_list, model_name, learning_rate=0.01):\n",
        "    \"\"\"\n",
        "    Entrena, evalúa y GUARDA el modelo Perceptrón en Google Drive.\n",
        "    \"\"\"\n",
        "\n",
        "    print(f\"\\n--- {model_name} (Features: {len(features_list)}) ---\")\n",
        "\n",
        "    # 1. Preparar datos filtrando las features seleccionadas\n",
        "    X_train_filtered = X_train[features_list]\n",
        "    X_test_filtered = X_test[features_list]\n",
        "\n",
        "    # 2. Inicializar y Entrenar Perceptrón\n",
        "    # eta0 es la tasa de aprendizaje, max_iter son las épocas\n",
        "    model = Perceptron(\n",
        "        eta0=learning_rate,\n",
        "        max_iter=50,\n",
        "        random_state=42,\n",
        "        shuffle=True,\n",
        "        n_jobs=-1,\n",
        "        tol=1e-3\n",
        "    )\n",
        "    model.fit(X_train_filtered, Y_train)\n",
        "\n",
        "    # 3. Guardar el modelo en Google Drive\n",
        "    model_filename = f\"{model_name.replace(' ', '_')}_LR{str(learning_rate).replace('.', 'p')}.joblib\"\n",
        "    save_path = os.path.join(DRIVE_PATH, model_filename)\n",
        "    joblib.dump(model, save_path)\n",
        "    print(f\"✅ Modelo GUARDADO en Google Drive en: {save_path}\")\n",
        "\n",
        "    # 4. Evaluación\n",
        "    Y_pred = model.predict(X_test_filtered)\n",
        "\n",
        "    # Métricas clave para el desbalance: Recall y Precisión para la clase 1 (Fraude)\n",
        "    recall = recall_score(Y_test, Y_pred)\n",
        "    precision = precision_score(Y_test, Y_pred)\n",
        "\n",
        "    print(f\"Features utilizadas: {', '.join(features_list[:min(len(features_list), 5)])}...\")\n",
        "    print(f\"Tasa de Aprendizaje (eta0): {learning_rate}\")\n",
        "    print(f\"Recall (Clase 1 - Fraude): {recall:.4f}\")\n",
        "    print(f\"Precisión (Clase 1 - Fraude): {precision:.4f}\")\n",
        "\n",
        "    # Mostrar reporte completo\n",
        "    print(\"\\nReporte de Clasificación:\")\n",
        "    print(classification_report(Y_test, Y_pred, target_names=['Legítimo (0)', 'Fraude (1)']))\n",
        "\n",
        "\n",
        "# --- 5. EJECUCIÓN DE LOS 3 MODELOS Y ANÁLISIS DEL IMPACTO DE LAS FEATURES ---\n",
        "\n",
        "print(\"\\n\\n#################################################################\")\n",
        "print(\"## INICIO DE LOS EXPERIMENTOS DEL PERCEPTRÓN 3: VARIACIÓN DE FEATURES\")\n",
        "print(\"#################################################################\")\n",
        "\n",
        "# 1. MODELO BASE (Perceptrón 1/2) - Usando todas las features\n",
        "train_save_and_evaluate_perceptron(\n",
        "    X_train_all, X_test_all, Y_train, Y_test,\n",
        "    features_list=FEATURES_A,\n",
        "    model_name=\"MODELO_BASE_FEATURES_A\",\n",
        "    learning_rate=0.01\n",
        ")\n",
        "\n",
        "# 2. PERCEPTRÓN 3 - VARIACIÓN B (Menor Dimensionalidad)\n",
        "# ÉNFASIS: ¿Ayuda la eliminación de features \"menos importantes\"?\n",
        "train_save_and_evaluate_perceptron(\n",
        "    X_train_all, X_test_all, Y_train, Y_test,\n",
        "    features_list=FEATURES_B,\n",
        "    model_name=\"PERCEPTRON_3_VARIACION_B\",\n",
        "    learning_rate=0.01\n",
        ")\n",
        "\n",
        "# 3. PERCEPTRÓN 3 - VARIACIÓN C (Features Clave)\n",
        "# ÉNFASIS: ¿Un subconjunto de features altamente discriminatorias mejora el rendimiento lineal?\n",
        "train_save_and_evaluate_perceptron(\n",
        "    X_train_all, X_test_all, Y_train, Y_test,\n",
        "    features_list=FEATURES_C,\n",
        "    model_name=\"PERCEPTRON_3_VARIACION_C\",\n",
        "    learning_rate=0.01\n",
        ")\n",
        "\n",
        "print(\"\\n\\n#################################################################\")\n",
        "print(\"## ¡EXPERIMENTO FINALIZADO!\")\n",
        "print(f\"Los modelos .joblib han sido guardados en su Drive en: {DRIVE_PATH}\")\n",
        "print(\"#################################################################\")"
      ]
    }
  ]
}